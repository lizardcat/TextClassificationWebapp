# Confidence Score Explained

## ðŸŽ¯ Quick Answer

**The confidence score is the probability that the model assigns to its predicted class.**

- If the model predicts "AI-Generated" with 87% probability, the confidence is **87%**
- If the model predicts "Human-Written" with 63% probability, the confidence is **63%**

The confidence tells you: **"How sure is the model about this prediction?"**

---

## ðŸ”¢ Mathematical Formula

```python
# Step 1: Get probabilities from neural network
probabilities = model.predict_proba(features)
# Returns: [P(Human), P(AI)]
# Example: [0.3521, 0.6479]

# Step 2: Get prediction (highest probability class)
prediction = model.predict(features)
# Returns: 0 (Human) or 1 (AI)
# Example: 1 (AI, because 0.6479 > 0.3521)

# Step 3: Confidence = probability of predicted class
if prediction == 1:  # AI-Generated
    confidence = probabilities[1] * 100
else:  # Human-Written
    confidence = probabilities[0] * 100

# Example: confidence = 0.6479 * 100 = 64.79%
```

**Key Insight:** The model always predicts the class with higher probability, so **confidence is always â‰¥ 50%**.

---

## ðŸ“Š Complete Processing Pipeline

```
User Input: "The essay text..."
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PREPROCESSING                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. clean_text()                              â”‚
â”‚    - Lowercase                               â”‚
â”‚    - Remove punctuation/numbers              â”‚
â”‚    - Trim spaces                             â”‚
â”‚    Output: "the essay text"                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FEATURE EXTRACTION                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. TF-IDF Vectorizer                         â”‚
â”‚    - Convert text to word importance scores  â”‚
â”‚    Output: [0.0, 0.23, 0.0, 0.45, ...]       â”‚
â”‚    Shape: (1, 1000) - 1000 features          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NORMALIZATION                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. StandardScaler                            â”‚
â”‚    - Normalize features (mean=0, std=1)      â”‚
â”‚    Output: [-1.2, 0.5, -0.3, 1.1, ...]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DIMENSIONALITY REDUCTION                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. PCA                                       â”‚
â”‚    - Reduce to principal components          â”‚
â”‚    Output: [-2.10]                           â”‚
â”‚    Shape: (1, 1) - reduced to 1 component    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NEURAL NETWORK                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 5. MLPClassifier (64â†’32 neurons)             â”‚
â”‚                                              â”‚
â”‚    Input: 1 neuron [-2.10]                   â”‚
â”‚      â†“                                       â”‚
â”‚    Hidden Layer 1: 64 neurons                â”‚
â”‚      [0.2, -1.3, 0.8, ..., 0.5]              â”‚
â”‚      â†“ (ReLU activation)                     â”‚
â”‚    Hidden Layer 2: 32 neurons                â”‚
â”‚      [1.1, 0.4, -0.7, ..., 0.9]              â”‚
â”‚      â†“ (ReLU activation)                     â”‚
â”‚    Output Layer: 2 neurons (raw logits)      â”‚
â”‚      [0.63, -0.27]                           â”‚
â”‚      â†“ (Softmax activation)                  â”‚
â”‚    Probabilities: [0.6469, 0.3531]           â”‚
â”‚                                              â”‚
â”‚ Softmax Formula:                             â”‚
â”‚   P(class_i) = e^(logit_i) / Î£(e^(logit_j)) â”‚
â”‚                                              â”‚
â”‚   P(Human) = e^0.63 / (e^0.63 + e^-0.27)     â”‚
â”‚            = 1.878 / (1.878 + 0.763)         â”‚
â”‚            = 0.6469 = 64.69%                 â”‚
â”‚                                              â”‚
â”‚   P(AI)    = e^-0.27 / (e^0.63 + e^-0.27)    â”‚
â”‚            = 0.763 / 2.641                   â”‚
â”‚            = 0.3531 = 35.31%                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PREDICTION & CONFIDENCE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 6. Select highest probability                â”‚
â”‚    max(64.69%, 35.31%) = 64.69%              â”‚
â”‚    â†’ Predicted class: 0 (Human-Written)      â”‚
â”‚                                              â”‚
â”‚ 7. Confidence = probability of predicted     â”‚
â”‚    confidence = 64.69%                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Final Output:
{
  "prediction": "Human-Written",
  "confidence": 64.69,
  "probabilities": {
    "human": 64.69,
    "ai": 35.31
  }
}
```

---

## ðŸ§® Why Probabilities Sum to 100%

The **softmax function** ensures all probabilities sum to 1.0 (100%):

```python
# Raw neural network outputs (logits)
logits = [0.63, -0.27]

# Apply softmax
exp_logits = [e^0.63, e^-0.27] = [1.878, 0.763]
sum_exp = 1.878 + 0.763 = 2.641

probabilities = [
    1.878 / 2.641 = 0.6469,  # 64.69%
    0.763 / 2.641 = 0.3531   # 35.31%
]

# Verify: 64.69% + 35.31% = 100% âœ“
```

**Key property**: When one probability goes up, the other must go down.

---

## ðŸ“ˆ Example Scenarios

### Scenario 1: High Confidence AI Text

```
Input: "In accordance with the predetermined parameters, the
        aforementioned entity proceeded to execute the designated
        protocol with optimal efficiency."

Neural Network Output:
â”œâ”€ P(Human) = 12.65%
â””â”€ P(AI)    = 87.35%

Prediction: "AI-Generated" (87.35% > 12.65%)
Confidence: 87.35% âœ“ HIGH CONFIDENCE
```

**Interpretation**: The model is very sure this is AI-generated text.

---

### Scenario 2: Low Confidence (Uncertain)

```
Input: "The project was completed on time and met all requirements."

Neural Network Output:
â”œâ”€ P(Human) = 52.18%
â””â”€ P(AI)    = 47.82%

Prediction: "Human-Written" (52.18% > 47.82%)
Confidence: 52.18% âš ï¸ LOW CONFIDENCE
```

**Interpretation**: The model is uncertain. The text has characteristics of both AI and human writing. You should be cautious about trusting this prediction.

---

### Scenario 3: High Confidence Human Text

```
Input: "omg I can't even rn!! yesterday was literally the CRAZIEST
        day ever lol like I'm still shook ðŸ˜‚"

Neural Network Output:
â”œâ”€ P(Human) = 94.82%
â””â”€ P(AI)    = 5.18%

Prediction: "Human-Written" (94.82% > 5.18%)
Confidence: 94.82% âœ“ HIGH CONFIDENCE
```

**Interpretation**: The model is very confident this is human-written (informal language, typos, emoji use).

---

## ðŸŽ¯ Confidence Thresholds & Reliability

| Confidence | Reliability | Should You Trust It? |
|------------|-------------|---------------------|
| **90-100%** | Very High | Yes - Model is very certain |
| **80-90%** | High | Mostly - Strong signal |
| **70-80%** | Good | Probably - Reasonable confidence |
| **60-70%** | Moderate | Maybe - Model is leaning toward this |
| **50-60%** | Low | Caution - Model is uncertain |
| **<50%** | N/A | Impossible (model predicts higher class) |

**Rule of Thumb**:
- **Above 80%**: Trust the prediction
- **60-80%**: Consider the context
- **Below 60%**: The model is guessing (close to 50/50)

---

## ðŸ” What Affects Confidence?

### High Confidence (90%+) When:

1. **Clear AI patterns**:
   - Formal, overly structured language
   - Perfect grammar and punctuation
   - Generic, corporate-sounding phrases
   - No typos or colloquialisms

2. **Clear Human patterns**:
   - Informal language, slang
   - Typos, grammatical errors
   - Personal anecdotes
   - Emotional language, emojis

### Low Confidence (50-60%) When:

1. **Ambiguous text**:
   - Neutral, factual statements
   - Simple sentences
   - Common phrases used by both AI and humans

2. **Mixed signals**:
   - Formal structure but personal touches
   - Perfect grammar but informal words
   - Text that could reasonably be either

3. **Short text**:
   - Not enough information for model to decide
   - Fewer distinguishing features

---

## ðŸ’¡ How to Use Confidence Scores

### For School/Research:

```python
if result['confidence'] >= 80:
    conclusion = "Strong evidence this is " + result['prediction']
elif result['confidence'] >= 65:
    conclusion = "Moderate evidence this is " + result['prediction']
else:
    conclusion = "Uncertain - needs human review"
```

### Decision Making:

- **High stakes** (academic integrity): Only act on 90%+ confidence
- **Screening** (flag for review): Use 70%+ confidence
- **Exploration** (just curious): Any confidence is interesting

### Improving Low Confidence:

If you get low confidence (<65%), try:

1. **Provide more text**: Longer passages give more signal
2. **Check for edge cases**: Very short or very generic text is hard to classify
3. **Consider context**: Use confidence as one factor, not the only factor
4. **Retrain model**: Use better training data (see TRAINING_GUIDE.md)

---

## ðŸ§ª Testing Confidence Calculation

You can verify the calculation yourself:

```python
# In your Python environment
import app

text = "Your test text here"
result = app.predict_text(text)

# Verify the math
human_prob = result['probabilities']['human']
ai_prob = result['probabilities']['ai']

# Check 1: Probabilities sum to 100%
assert abs(human_prob + ai_prob - 100.0) < 0.01, "Probabilities don't sum to 100!"

# Check 2: Confidence matches predicted class probability
if result['prediction'] == 'Human-Written':
    assert result['confidence'] == human_prob
elif result['prediction'] == 'AI-Generated':
    assert result['confidence'] == ai_prob

# Check 3: Model predicts higher probability class
max_prob = max(human_prob, ai_prob)
assert result['confidence'] == max_prob, "Confidence should be max probability!"

print("âœ“ All confidence checks passed!")
```

---

## ðŸŽ“ Summary

**Confidence Score = Probability of the Predicted Class**

- Calculated using softmax function on neural network outputs
- Always between 50-100% (model predicts higher probability)
- Higher confidence = more certain prediction
- Lower confidence = model is uncertain (close to 50/50)
- Use confidence to assess prediction reliability

**Visual Representation in UI:**

```
Prediction: AI-Generated
Confidence: 87.35%

Human-Written: 12.65% [â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘]
AI-Generated:  87.35% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘]
```

The progress bars show both probabilities, and the confidence score highlights how sure the model is about its choice.
